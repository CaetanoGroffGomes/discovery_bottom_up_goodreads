# ğŸ“š Discovery Bottom-Up com Dados - Goodreads

Projeto prÃ¡tico de **Product Discovery orientado a dados**, explorando como Machine Learning e anÃ¡lise de dados podem revelar oportunidades de produto e validar hipÃ³teses tÃ©cnicas.

## ğŸ¯ Sobre o Projeto

Este projeto demonstra um processo completo de **discovery bottom-up** usando dados reais de livros do Goodreads. O objetivo Ã© mostrar como gestores de produto podem avaliar a viabilidade tÃ©cnica de soluÃ§Ãµes baseadas em dados antes de priorizÃ¡-las.

### ğŸ“– Contexto

Baseado no artigo "Discovery Bottom-Up com Dados", este projeto ilustra:
- Como avaliar qualidade e estrutura de dados
- Identificar o que Ã© possÃ­vel (e o que nÃ£o Ã©) com dados disponÃ­veis
- Validar hipÃ³teses tÃ©cnicas atravÃ©s de POCs (Provas de Conceito)
- Conectar soluÃ§Ãµes tÃ©cnicas com objetivos de negÃ³cio

## ğŸ—‚ï¸ Estrutura do Projeto

```
.
â”œâ”€â”€ data/                          # Dados originais (nÃ£o versionados)
â”‚   â””â”€â”€ book1-100k.csv            # Dataset Goodreads (~58k livros)
â”‚
â”œâ”€â”€ exports/                       # Todos os outputs do projeto
â”‚   â”œâ”€â”€ clean_data/               # Dados limpos e processados
â”‚   â”œâ”€â”€ clustering/               # Resultados de clusterizaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ analysis/            # AnÃ¡lises e visualizaÃ§Ãµes
â”‚   â”œâ”€â”€ duplicatas/               # AnÃ¡lises de ISBN e duplicatas
â”‚   â””â”€â”€ eda/                      # AnÃ¡lise exploratÃ³ria
â”‚
â”œâ”€â”€ scripts/                       # Scripts Python organizados
â”‚   â”œâ”€â”€ 01_limpeza_dados.py
â”‚   â”œâ”€â”€ 02_analise_eda.py
â”‚   â”œâ”€â”€ 03_clustering_poc.py
â”‚   â”œâ”€â”€ 04_isbn_validacao.py
â”‚   â””â”€â”€ 05_visualizar_clusters.py
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter notebooks (opcional)
â”‚   â””â”€â”€ goodreads_book1-100_eda.ipynb
â”‚
â”œâ”€â”€ requirements.txt               # DependÃªncias Python
â””â”€â”€ README.md                      # Este arquivo
```

## ğŸš€ ComeÃ§ando

### PrÃ©-requisitos

- Python 3.8 ou superior
- pip (gerenciador de pacotes Python)

### InstalaÃ§Ã£o

1. **Clone o repositÃ³rio:**
```bash
git clone <url-do-repositorio>
cd discovery-bottom-up-dados
```

2. **Crie um ambiente virtual (recomendado):**
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

3. **Instale as dependÃªncias:**
```bash
pip install -r requirements.txt
```

4. **Coloque o dataset na pasta correta:**
```bash
# Crie a pasta data/ e adicione o arquivo book1-100k.csv
mkdir data
# Baixe o dataset do Kaggle e coloque em data/book1-100k.csv
```

## ğŸ“Š Pipeline de AnÃ¡lise

### 1ï¸âƒ£ Limpeza e PreparaÃ§Ã£o dos Dados

```bash
python scripts/01_limpeza_dados.py
```

**O que faz:**
- Carrega e padroniza nomes de colunas
- Trata valores ausentes e outliers
- Normaliza datas de publicaÃ§Ã£o
- Cria dataset limpo em `exports/clean_data/`

**Principais descobertas:**
- 58% de dados ausentes em `pageNumbers`
- 65% de dados ausentes em `Language`
- Datas de publicaÃ§Ã£o com outliers (livros em 3006!)
- ISBN com ~1% de valores nulos

### 2ï¸âƒ£ AnÃ¡lise ExploratÃ³ria (EDA)

```bash
python scripts/02_analise_eda.py
```

**O que faz:**
- EstatÃ­sticas descritivas completas
- DistribuiÃ§Ãµes de variÃ¡veis
- AnÃ¡lise de correlaÃ§Ãµes
- IdentificaÃ§Ã£o de padrÃµes temporais
- VisualizaÃ§Ãµes exportadas

**Outputs:**
- `exports/eda/` - GrÃ¡ficos e relatÃ³rios
- EstatÃ­sticas por dÃ©cada, autor, lÃ­ngua, publisher

### 3ï¸âƒ£ ValidaÃ§Ã£o de ISBN e Duplicatas

```bash
python scripts/04_isbn_validacao.py
```

**O que faz:**
- Valida ISBNs usando algoritmos de check digit
- Detecta duplicatas usando chave forte (ISBN)
- Identifica problemas de normalizaÃ§Ã£o
- Exporta relatÃ³rios detalhados

**Principais descobertas:**
- 194 duplicatas encontradas via ISBN
- ISBNs-10 e ISBN-13 misturados
- Necessidade de canonizaÃ§Ã£o de dados

### 4ï¸âƒ£ Prova de Conceito - Clustering

```bash
python scripts/03_clustering_poc.py
```

**O que faz:**
- Implementa K-Means e Hierarchical Clustering
- Usa TF-IDF para vetorizaÃ§Ã£o de texto
- Avalia qualidade dos clusters (Silhouette, Davies-Bouldin)
- Aplica PCA para reduÃ§Ã£o dimensional
- Exporta clusters e mÃ©tricas

**Features utilizadas:**
- Nome do livro (TF-IDF)
- Autor
- LÃ­ngua
- Ano de publicaÃ§Ã£o
- Publisher

**Resultados:**
- âœ… **Sucesso tÃ©cnico**: Clusters foram criados
- âš ï¸ **LimitaÃ§Ã£o de valor**: Agrupamentos muito genÃ©ricos
- ğŸ“‹ **ConclusÃ£o**: Dados insuficientes para recomendaÃ§Ãµes satisfatÃ³rias

### 5ï¸âƒ£ AnÃ¡lise Visual dos Clusters

```bash
python scripts/05_visualizar_clusters.py
```

**O que faz:**
- Gera tabelas interativas HTML
- Cria visualizaÃ§Ãµes comparativas
- Exporta anÃ¡lise detalhada de cada cluster
- Identifica caracterÃ­sticas distintivas

**Outputs:**
- `cluster_table.html` - Tabela interativa com busca
- `cluster_simple.html` - VisÃ£o simplificada em cards
- `cluster_analysis.html` - RelatÃ³rio completo
- GrÃ¡ficos comparativos (PNG)

## ğŸ“ Aprendizados e ConclusÃµes

### âœ… Viabilidade de NegÃ³cio
**SoluÃ§Ã£o proposta:** Agrupamento de livros similares para recomendaÃ§Ã£o inteligente

**Impacto esperado:**
- âœ… Aumentar engajamento na plataforma
- âœ… Melhorar descoberta de livros
- âœ… Potencial aumento em cliques afiliados

### âš ï¸ Viabilidade TÃ©cnica

**Status:** Parcialmente viÃ¡vel com limitaÃ§Ãµes

**Dados disponÃ­veis:**
- âœ… TÃ­tulo, autor, ano, lÃ­ngua, publisher
- âŒ DescriÃ§Ã£o/sinopse dos livros
- âŒ GÃªneros/categorias
- âŒ Reviews e comentÃ¡rios
- âŒ Dados de usuÃ¡rios
- âŒ HistÃ³rico de leitura

**ConclusÃ£o:**
> "Apenas com tÃ­tulo, lÃ­ngua, autor, ano de publicaÃ§Ã£o e dados gerais, os agrupamentos de livros sÃ£o muito genÃ©ricos e nÃ£o entregam valor de uma recomendaÃ§Ã£o satisfatÃ³ria."

### ğŸ“Š Problemas Identificados

1. **Pipeline de dados:**
   - Falta de normalizaÃ§Ã£o (autores, publishers)
   - AusÃªncia de canonizaÃ§Ã£o (194 duplicatas por ISBN, ~3074 por TF-IDF)
   - Outliers temporais nÃ£o tratados

2. **Qualidade de cadastros:**
   - Campos nÃ£o normalizados
   - ValidaÃ§Ãµes fracas durante cadastro
   - Dados inconsistentes

3. **Completude:**
   - Dados crÃ­ticos ausentes (descriÃ§Ã£o, gÃªnero, reviews)
   - Sem dados de usuÃ¡rios
   - Sem histÃ³rico de interaÃ§Ãµes

## ğŸ”„ PrÃ³ximos Passos

### Curto Prazo
1. **Melhorar pipeline de dados:**
   - Implementar validaÃ§Ãµes no cadastro
   - Normalizar autores e publishers
   - Canonizar dados existentes

2. **Testar abordagens alternativas:**
   - DBSCAN para clusters de densidade
   - Outros mÃ©todos de embedding (BERT)
   - CombinaÃ§Ã£o de mÃºltiplos modelos

### MÃ©dio Prazo
3. **Adquirir dados complementares:**
   - Scraping de descriÃ§Ãµes/sinopses
   - IntegraÃ§Ã£o com APIs de livros
   - Coleta de gÃªneros via crowdsourcing

4. **Dados de usuÃ¡rios:**
   - HistÃ³rico de leitura
   - Reviews e avaliaÃ§Ãµes
   - InteraÃ§Ãµes sociais

### Longo Prazo
5. **Nova POC com dados completos:**
   - RecomendaÃ§Ã£o colaborativa
   - Hybrid models (conteÃºdo + colaborativo)
   - A/B testing com usuÃ¡rios reais

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.8+**
- **pandas** - ManipulaÃ§Ã£o de dados
- **numpy** - ComputaÃ§Ã£o numÃ©rica
- **scikit-learn** - Machine Learning (clustering, TF-IDF, PCA)
- **matplotlib** - VisualizaÃ§Ãµes

## ğŸ“š ReferÃªncias e Recursos

### Conceitos Abordados
- Discovery bottom-up em produto
- AnÃ¡lise exploratÃ³ria de dados (EDA)
- CanonizaÃ§Ã£o de dados
- Clustering nÃ£o-supervisionado
- ValidaÃ§Ã£o de hipÃ³teses tÃ©cnicas

### Modelos de ML Mencionados
- **ClusterizaÃ§Ã£o:** K-Means, Hierarchical, DBSCAN
- **Embeddings:** TF-IDF, BERT, word2vec
- **ClassificaÃ§Ã£o:** Decision Trees, Random Forest, XGBoost
- **RecomendaÃ§Ã£o:** Collaborative Filtering, Content-Based

### Links Ãšteis
- [Kaggle - Goodreads Dataset](https://www.kaggle.com/)
- [Scikit-learn Documentation](https://scikit-learn.org/)
- [Hugging Face - Models](https://huggingface.co/models)

## ğŸ’¡ Para Gestores de Produto

### O que Este Projeto Ensina

1. **Avaliar antes de priorizar:**
   - Nem toda ideia com dados Ã© tecnicamente viÃ¡vel
   - POCs baratas validam hipÃ³teses antes de investir

2. **Qualidade > Quantidade:**
   - Ter dados nÃ£o Ã© suficiente
   - Dados limpos e canonizados sÃ£o essenciais

3. **Entender o possÃ­vel:**
   - Machine Learning tem aplicaÃ§Ãµes bem definidas
   - Conhecer as ferramentas disponÃ­veis expande possibilidades

4. **Riscos probabilÃ­sticos:**
   - SoluÃ§Ãµes de ML/AI sempre erram
   - Avaliar impacto do erro Ã© crucial
   - IntervenÃ§Ã£o humana pode ser necessÃ¡ria

### Framework de DecisÃ£o

```
Ideia com dados
    â†“
Avaliar qualidade dos dados
    â†“
Identificar o que Ã© possÃ­vel
    â†“
POC tÃ©cnica rÃ¡pida
    â†“
Dados suficientes? â†’ NÃƒO â†’ Adquirir dados ou pivotar
    â†“ SIM
Valor entregue satisfatÃ³rio? â†’ NÃƒO â†’ Testar alternativas
    â†“ SIM
Conectar com objetivos de negÃ³cio
    â†“
Priorizar ou descartar
```

## ğŸ“„ LicenÃ§a

Este projeto Ã© um material educacional baseado no artigo "Discovery Bottom-Up com Dados".

## ğŸ‘¥ Autor

Projeto criado como demonstraÃ§Ã£o prÃ¡tica de product discovery orientado a dados.

---

## ğŸ” AnÃ¡lise Detalhada do Dataset

### Colunas e Qualidade

| Coluna | Tipo | ObrigatÃ³rio | Normalizado | % Null/InvÃ¡lido | Uso em ML |
|--------|------|-------------|-------------|-----------------|-----------|
| id | int | âœ… Sim | âœ… Sim | 0% | Chave primÃ¡ria |
| name | str | âœ… Sim | âŒ NÃ£o | 0% | âœ… Feature principal |
| pageNumbers | int | âŒ NÃ£o | âœ… Sim | 58% | âš ï¸ Limitado |
| publishMonth | int | âœ… Sim | âœ… Sim | 0% | âœ… Feature temporal |
| publishDay | int | âœ… Sim | âœ… Sim | 0% | âœ… Feature temporal |
| publishYear | int | âœ… Sim | âŒ NÃ£o | ~0% | âœ… Feature temporal |
| publisher | str | âŒ NÃ£o | âŒ NÃ£o | 0.8% | âš ï¸ Requer normalizaÃ§Ã£o |
| countsOfReview | int | âœ… Sim | âœ… Sim | 0% | âœ… Popularidade |
| language | str | âŒ NÃ£o | âŒ NÃ£o | 65% | âš ï¸ Muito ausente |
| authors | str | âœ… Sim | âŒ NÃ£o | 0% | âš ï¸ Requer normalizaÃ§Ã£o |
| rating | decimal | âœ… Sim | âœ… Sim | 0% | âœ… Qualidade |
| isbn | int | âŒ NÃ£o | âŒ NÃ£o | 0.9% | âš ï¸ Chave fraca |

### Problemas Identificados

#### ğŸ”´ CrÃ­ticos
- Falta de descriÃ§Ã£o/sinopse dos livros
- Falta de gÃªneros/categorias
- AusÃªncia de dados de usuÃ¡rios
- 65% de dados ausentes em lÃ­ngua

#### ğŸŸ¡ Importantes
- Autores nÃ£o normalizados (duplicatas)
- Publishers nÃ£o normalizados
- ISBN com duplicatas e inconsistÃªncias
- Outliers temporais (livros em 3006)

#### ğŸŸ¢ Menores
- PageNumbers com muitos nulos (58%)
- Datas separadas em 3 colunas
- Formato CSV (lento para produÃ§Ã£o)

---

## ğŸ“ Suporte

Para dÃºvidas sobre o projeto:
1. Leia a documentaÃ§Ã£o completa
2. Revise o artigo "Discovery Bottom-Up com Dados"
3. Analise os notebooks e scripts
4. Abra uma issue no repositÃ³rio

---

**ğŸ¯ Lembre-se:** O objetivo nÃ£o Ã© ter a melhor soluÃ§Ã£o tÃ©cnica, mas **validar se seus dados permitem entregar valor real ao usuÃ¡rio antes de priorizar a soluÃ§Ã£o**.
